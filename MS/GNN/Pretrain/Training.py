import torch
import torch.nn as nn
import torch.optim as optim

from .DijkstraGnn import get_pyg_data_from_nx, generate_expert_label, GNNPretrainModel, GLOBAL_STATS, DynamicGraphDataset, DataLoader
from ...Env.NetworkGenerator import TopologyGenerator

if __name__ == "__main__":
  print("ğŸš€ å¼€å§‹é˜¶æ®µ 1B: GNN ä¸»ä½“é¢„è®­ç»ƒ (Mini-batch DataLoader æ¨¡å¼)...")

  # --- 1. è¶…å‚æ•°é…ç½® ---
  EPOCHS = 100          # æ€»è½®æ•°å¯ä»¥é€‚å½“å‡å°‘ï¼Œå› ä¸ºç°åœ¨æ¯è½®çœ‹çš„å›¾å¤šäº†
  GNN_DIM = 128         # å»ºè®®å¢åŠ å®½åº¦
  NUM_LAYERS = 6        # [é‡è¦] å»ºè®®å¢åŠ æ·±åº¦ä»¥è¦†ç›–ç½‘ç»œç›´å¾„
  BATCH_SIZE = 64       # [å…³é”®] çœŸæ­£çš„å°æ‰¹é‡å¤§å°
  LEARNING_RATE = 1e-3  # Batchå˜å¤§åï¼Œå­¦ä¹ ç‡é€šå¸¸å¯ä»¥ç¨å¾®è°ƒå¤§ä¸€ç‚¹
  SAMPLES_PER_EPOCH = 6400 # æ¯ä¸ª epoch æ€»å…±çœ‹å¤šå°‘å¼ å›¾ (6400 / 64 = 100 steps)
  
  NODE_FEAT_DIM = 3     # å‡è®¾ä½ é‡‡ç”¨äº†æˆ‘ä¹‹å‰å»ºè®®çš„ BFS Hop ç‰¹å¾ï¼Œå¦‚æœæ˜¯æ—§çš„åˆ™ä¸º 3
  EDGE_FEAT_DIM = 2

  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  print(f"Using device: {device}")

  # --- 2. åˆå§‹åŒ–ç»„ä»¶ ---
  topo_gen = TopologyGenerator(num_nodes_range=(20, 30), m_ba=2)                           # topo generator
  model = GNNPretrainModel(NODE_FEAT_DIM, GNN_DIM, EDGE_FEAT_DIM, NUM_LAYERS).to(device)   # gnn model
  optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)                             # optimizer 

  # [é‡è¦] å›ºå®š pos_weight ä»¥é˜²æ­¢éœ‡è¡ã€‚
  # æ ¹æ®ç»éªŒï¼Œ20-30èŠ‚ç‚¹çš„å›¾ï¼Œè´Ÿè¾¹å¤§çº¦æ˜¯æ­£è¾¹çš„ 15-25 å€ã€‚
  # æˆ‘ä»¬å–ä¸€ä¸ªä¿å®ˆå€¼ 15.0ï¼Œè®©æ¨¡å‹ç¨å¾®å¤šé¢„æµ‹ä¸€ç‚¹æ­£æ ·æœ¬ï¼Œä¿è¯ Recallã€‚
  POS_WEIGHT_FIXED = torch.tensor([15.0]).to(device)
  loss_fn = nn.BCEWithLogitsLoss(pos_weight=POS_WEIGHT_FIXED)

  # FiLM ä¸­å’Œå‚æ•°
  GAMMA_NEUTRAL = torch.ones((NUM_LAYERS, GNN_DIM), dtype=torch.float).to(device)
  BETA_NEUTRAL = torch.zeros((NUM_LAYERS, GNN_DIM), dtype=torch.float).to(device)

  # --- 3. è®­ç»ƒå¾ªç¯ ---
  for epoch in range(EPOCHS):
    model.train()
  
    # [å…³é”®] æ¯ä¸ª epoch é‡æ–°åˆ›å»º Dataset å’Œ DataLoader
    # è¿™æ˜¯ä¸ºäº†è®©æ–°çš„ epoch èƒ½ç”Ÿæˆæ–°çš„éšæœºå›¾ï¼Œä¿æŒæ•°æ®çš„æ— é™å¤šæ ·æ€§
    dataset = DynamicGraphDataset(topo_gen, GLOBAL_STATS, max_samples_per_epoch=SAMPLES_PER_EPOCH)
    # num_workers > 0 å¯ä»¥å¤šè¿›ç¨‹ç”Ÿæˆå›¾ï¼ŒåŠ é€Ÿè®­ç»ƒï¼Œä½†å¯èƒ½éœ€è¦å¤„ç†ä¸€äº›å¤šè¿›ç¨‹å…±äº«ç§å­çš„ç»†èŠ‚
    # è¿™é‡Œå…ˆç”¨ num_workers=0 (ä¸»è¿›ç¨‹ç”Ÿæˆ) ä¿è¯ç®€å•ç¨³å®š
    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=0) 

    total_loss = 0.0
    total_acc = 0.0
    num_batches = 0

    # ä½¿ç”¨ tqdm åŒ…è£… loader ä»¥æ˜¾ç¤ºè¿›åº¦æ¡
    pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}", unit="batch")
    
    for batch_data in pbar:
      # batch_data æ˜¯ä¸€ä¸ª "å·¨å›¾"ï¼ŒåŒ…å«äº† BATCH_SIZE (e.g., 64) ä¸ªå°å›¾
      # å®ƒçš„ .edge_index, .x, .edge_attr éƒ½æ˜¯è‡ªåŠ¨æ‹¼æ¥å¥½çš„
      batch_data = batch_data.to(device)
      
      optimizer.zero_grad()
      
      # å‰å‘ä¼ æ’­ï¼šæ¨¡å‹åƒå¤„ç†ä¸€ä¸ªå¤§å›¾ä¸€æ ·å¤„ç†è¿™ä¸ª batch
      edge_logits = model(batch_data, manual_gamma=GAMMA_NEUTRAL, manual_beta=BETA_NEUTRAL)
      
      # è®¡ç®—æŸå¤±ï¼šbatch_data.y åŒ…å«äº†è¿™ 64 ä¸ªå›¾çš„æ‰€æœ‰è¾¹çš„æ ‡ç­¾
      loss = loss_fn(edge_logits, batch_data.y)
      
      loss.backward()
      
      # [å¯é€‰] æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢çˆ†ç‚¸
      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
      
      optimizer.step()

      # ç»Ÿè®¡æŒ‡æ ‡
      current_loss = loss.item()
      total_loss += current_loss
      
      # ç®€å•å‡†ç¡®ç‡
      predicted = (edge_logits > 0.0).float()
      current_acc = (predicted == batch_data.y).float().mean().item()
      total_acc += current_acc
      num_batches += 1
      
      # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
      pbar.set_postfix({"Loss": f"{current_loss:.4f}", "Acc": f"{current_acc:.2%}"})

    # Epoch ç»“æŸæ€»ç»“
    avg_loss = total_loss / num_batches
    avg_acc = total_acc / num_batches
    print(f"Epoch {epoch+1} å®Œæˆ. Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.2%}")

  # 6. ä¿å­˜é¢„è®­ç»ƒå¥½çš„ GNN ä¸»ä½“
  # æ³¨æ„ï¼šä¿å­˜çš„æ˜¯æ•´ä¸ªæ¨¡å‹ï¼Œåœ¨é˜¶æ®µ 2 åŠ è½½æ—¶éœ€è¦é€‰æ‹©æ€§åŠ è½½
  print("âœ… é˜¶æ®µ 1B å®Œæˆã€‚ä¿å­˜ GNN ä¸»ä½“æƒé‡...")
  # æˆ‘ä»¬åªä¿å­˜ GNN ä¸»ä½“ï¼ˆå·ç§¯å±‚ã€å½’ä¸€åŒ–å±‚ï¼‰å’ŒèŠ‚ç‚¹åµŒå…¥å±‚çš„æƒé‡
  # ä¸¢å¼ƒ self.edge_output_head
  gnn_body_weights = {k: v for k, v in model.state_dict().items() if 'edge_output_head' not in k}
  torch.save(gnn_body_weights, 'pretrained-model-with-posWeight.pth')